## kNN

#### 原理

- 分类过程？
 准备一个训练数据集，计算测试数据跟训练集中每个数据的距离，距离越小表示相关程度越大；
取前k个相关程度最大的数据，这些数据中最多的分类就是被测试数据的类型。

- 如何计算数据之间的距离？
 数据用向量表示，用欧几里得距离计算两个向量的距离。
 
#### 优缺点
- 优点
    - k-近邻算法是分类数据最简单最有效的算法。
- 缺点
    - 耗空间：k-近邻算法是基于实例的学习,使用算法时我们必须有接近实际数据的训练样本数据。k-近邻算法必须保存全部数据集,如果训练数据集的很大,必须使用大量的存储空间。
    - 耗时：由于必须对数据集中的每个数据计算距离值,实际使用时可能非常耗时。
    - 数据不透明：它无法给出任何数据的基础结构信息,因此我们也无法知晓平均实例样本和典型实例样本具有什么特征。
